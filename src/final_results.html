<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">

<title>Howdy Everyone!!!</title>
<meta name="description" content="I will soon update my Blogs here Stay tuned.">

<link rel="stylesheet" href="css/main.css">
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-175506696-1', 'auto');
  ga('send', 'pageview');
</script>


</head>
<body>
  <header class="site-header">
  <div class="container">
    <input type="checkbox" id="toggleNavbar">
    <h1 class="logo"><a href="/">Home</a></h1>
    <label for="toggleNavbar" role="button" class="toggle-navbar-button">
      <i class="icon icon-menu"></i>
      <i class="icon icon-cross"></i>
    </label>
    <nav class="navbar">
      <ul>
        
        <li><a href="/" title="About">home</a></li>
        
        <li><a href="/data.html" title="Blog">Data</a></li>
      </ul>
    </nav>
  </div>
</header>


<main class="main-container">
  <div class="container">
    <article role="article" class="post">

  <div class="card">
    <header class="post-header">
      <h1 class="post-title">Results</h1>
      <em class="post-meta">
      </em>
    </header>

    <div class="post-content">
      
      <p>
        Based on the results obtained, it is found that Gradient Boosting Regressor consistently performs the best. This is followed by Bagging Regressor, Random Forest Regressor, Adaboost Regressor and by K Neighbour Regressor. Bagging Regressor is found to perform well as Bagging (Bootstrap sampling)
        relies on the fact that the combination of many independent base learners will significantly decrease the error. Therefore we want to produce as many independent base learners as possible. Each base learner is generated by sampling the original data set with replacement. From the results,
         it is safe to say that additional hidden layer(s) improve upon the score of the models. Random Forest is an extension of bagging where the major difference is the incorporation of randomized feature selection. 

         <img src="images/gbr.png" alt="Girl in a jacket" width="900" height="600">
    </p>

    </div>

    

  </div>

</article>

  </div>
</main>

<footer class="site-footer">
  <div class="container">
    <p class="txt-medium-gray">
      <small>&copy;2020 All rights reserved. Made with <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> and â™¥</small>
    </p>
  </div>
</footer>


</body>
</html>